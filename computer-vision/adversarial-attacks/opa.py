import torch
from torch import nn
import torch.nn.functional as F
import numpy as np

from src.utils import visualize_perturbations


class OnePixelAttack:
    """
    This class implements the black-box adversarial attack One Pixel Attack (OPA).
    """

    def __init__(
        self, model: nn.Module, img: torch.Tensor, label: int, n: int = 100
    ) -> None:
        """
        Constructor of the class.

        Parameters
        ----------
        model : Model used.
        img   : Original image. Dimensions: [channels, height, width].
        label : Real label for the image.
        n     : Size of the population.
        """

        # Class attributes
        self.n = n
        self.F = 0.5
        self.img = img
        self.perturbed_img = img.clone()
        self.label = label
        self.model = model

        # Create and evaluate population
        self.population = torch.rand(n, 5)
        self.fitness = self._evaluate_population()
        with torch.no_grad():
            prob = self.model(img.unsqueeze(0)).squeeze()
        self.historical_fitness = [F.softmax(prob, dim=0)[self.label].item()]

    @staticmethod
    def _add_perturbation(
        perturbations: list[torch.Tensor], img: torch.Tensor
    ) -> torch.Tensor:
        """
        Adds a finite number of perturbations (specifically len(perturbations)).

        Parameters
        ----------
        perturbations : Perturbations to made. Dimensions of each perturbation: [5].
        img           : Image to which perturbations are applied. Dimensions: [channels,
                        height, width].

        Returns
        -------
        p_ img : Perturbed image. Dimensions: [channels, height, width].
        """

        # TODO
        p_img = img.clone()
        for pert in perturbations:
            pert = torch.clamp(pert, 0, 1)
            index_i = round(pert[0].item() * img.shape[1])
            index_j = round(pert[1].item() * img.shape[2])

            index_i = min(index_i, img.shape[1] - 1)
            index_j = min(index_j, img.shape[2] - 1)

            p_img[:, index_i, index_j] = torch.clamp(pert[2:], 0, 1)
        return p_img

    def _fitness_function(self, perturbed_img: torch.Tensor) -> float:
        """
        Calculates the fitness of the perturbed image generated by an individual.

        Parameters
        ----------
        perturbed_img : Perturbed image generated by an individual. Dimensions:
                        [channels, height, width].

        Returns
        -------
        Probability asigned by the model to the real class.
        """

        with torch.no_grad():
            prob = self.model(perturbed_img.unsqueeze(0)).squeeze()

        return F.softmax(prob, dim=0)[self.label].item()

    def _evaluate_population(self) -> torch.Tensor:
        """
        Evaluates the fitness of the entire population.

        Returns
        -------
        fitness : Fitness of the entire population. Dimensions: [self.n, 1].
        """

        # TODO
        fitness = torch.zeros(self.n, 1)
        for i in range(self.n):
            perturbed_img = self._add_perturbation(
                [self.population[i]], self.perturbed_img
            )
            fitness[i] = self._fitness_function(perturbed_img)
        return fitness

    def _generate_new_population(self) -> None:
        """
        Updates the population based on the algorithm x_i = x_r1 + F * (x_r2 - x_r3)
        and selects the best between each child and parent.
        """

        # TODO
        new_population = torch.zeros_like(self.population)
        for i in range(self.n):
            r1, r2, r3 = np.random.choice(self.n, 3, replace=False)
            new_population[i] = self.population[r1] + self.F * (
                self.population[r2] - self.population[r3]
            )
            new_population[i] = torch.clamp(new_population[i], 0, 1)
        new_fitness = self._evaluate_population()
        for i in range(self.n):
            if new_fitness[i] < self.fitness[i]:
                self.population[i] = new_population[i]
                self.fitness[i] = new_fitness[i]

    def _get_perturbations(
        self, epochs: int, d: int, print_every: int | None
    ) -> list[torch.Tensor]:
        """
        Obtains the perturbations using differential evolution.

        Parameters
        ----------
        epochs      : Number of epochs we train.
        d           : Number of pixels we change.
        print_every : Number of epochs we print the training phase.

        Returns
        -------
        perturbations : Bet perturbations found. Dimensions of each perturbation: [d, 5]
        """

        # TODO
        perturbations = []
        for pixel in range(d):
            self.population = torch.rand(self.n, 5)
            self.fitness = self._evaluate_population()
            for epoch in range(epochs):
                self._generate_new_population()
                self.historical_fitness.append(max(self.fitness).item())
                if print_every is not None and epoch % print_every == 0:
                    print(f"Epoch: {epoch} - Fitness: {self.historical_fitness[-1]}")
            best_individual = self.population[torch.argmin(self.fitness)]
            perturbations.append(best_individual)
            self.perturbed_img = self._add_perturbation(
                [best_individual], self.perturbed_img
            )
        return perturbations

    def perturb_img(
        self,
        epochs: int = 50,
        d: int = 1,
        print_every: int | None = None,
        show: bool = True,
        title: str | None = None,
    ) -> tuple[torch.Tensor, list[torch.Tensor]]:
        """
        Perturbs an image.

        Parameters
        ----------
        epochs      : Number of epochs we train.
        d           : Number of pixels we change.
        print_every : Number of epochs we print the training phase.
        show        : Boolean parameter that decides whether to save the figure or not.
        title       : Title of the image in case it is saved.

        Returns
        -------
        perturbed_img : Perturbed image. Dimensions: [channels, height, width].
        perturbations : Perturbations made. Dimensions of each perturbation: [channels,
                        height, width].
        """

        # TODO
        self.perturbed_img = self.img.clone()
        perturbations = self._get_perturbations(epochs, d, print_every)

        if show:
            visualize_perturbations(
                self.perturbed_img, self.img, self.label, self.model, title
            )

        return self.perturbed_img, perturbations
